{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dimenet-materials-predictions.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wLPWOjsDs0js"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLnbZNvlsPV3"
      },
      "source": [
        "# Initial Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "parGhnmT4wBE"
      },
      "source": [
        "\n",
        "\n",
        "*   Make sure you run the model using a GPU (On Google Colab: Runtime -> Change Runtime Type -> GPU)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8XBE1QSsEgV"
      },
      "source": [
        "#@title  { vertical-output: true, display-mode: \"both\" }\n",
        "\n",
        "# install packages\n",
        "!pip install -q torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "!pip install -q torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git\n",
        "!pip install -q torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "!pip install -q ase"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9FcqH-QsS9N"
      },
      "source": [
        "#@title  { vertical-output: true, display-mode: \"both\" }\n",
        "import numpy as np\n",
        "import torch\n",
        "import ase\n",
        "import random\n",
        "from torch_geometric.data import DataLoader\n",
        "from ase.io import read\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# set random seeds\n",
        "seed = 55555\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "# if you are using GPU\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G84ITmF4sU4-"
      },
      "source": [
        "#@title  { vertical-output: true, display-mode: \"both\" }\n",
        "\n",
        "BASE_PATH = '/content/drive/MyDrive/FeMaterials/'\n",
        "TRAINING_RATIO = 0.8\n",
        "NUCLEAR_CHARGE = 26 # default nuclear charge\n",
        "OPTIMIZER = torch.optim.Adam\n",
        "DTYPE = torch.float64\n",
        "\n",
        "BATCH_SIZE = 6\n",
        "CRITERION = torch.nn.MSELoss()\n",
        "CROSSENTROPY = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "def print_hyperparameters():\n",
        "  print(\"Default nuclear charge:\", NUCLEAR_CHARGE)\n",
        "  print(\"Training ratio:\", TRAINING_RATIO)\n",
        "  print(\"Batch size:\", BATCH_SIZE)\n",
        "  print(\"Optimizer:\", OPTIMIZER)\n",
        "  print(\"Learning rate:\", LEARNING_RATE)\n",
        "  print(\"Criterion:\", CRITERION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dl7trcesZtt"
      },
      "source": [
        "#@title  { vertical-output: true, display-mode: \"both\" }\n",
        "import time\n",
        "from datetime import datetime\n",
        "import os\n",
        "from numpy import savetxt\n",
        "\n",
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path2data = BASE_PATH + 'input/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLPWOjsDs0js"
      },
      "source": [
        "# Pre-Processing Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_W0som4s3Wb"
      },
      "source": [
        "#@title  { vertical-output: true, display-mode: \"both\" }\n",
        "M_1_54 = None\n",
        "\n",
        "def extend_atoms(atoms: ase.Atoms, target: int):\n",
        "  global M_1_54\n",
        "  tmp = None\n",
        "  if M_1_54 is None or target != 54:\n",
        "    tmp = ase.build.find_optimal_cell_shape(atoms.get_cell(), target, \"sc\") \n",
        "    if target == 54:\n",
        "      M_1_54 = tmp\n",
        "  else:\n",
        "    tmp = M_1_54\n",
        "  supercell = ase.build.make_supercell(atoms, tmp)\n",
        "  supercell.info[\"energy\"] = atoms.info[\"energy\"] * int(target / atoms.get_global_number_of_atoms())\n",
        "  return supercell"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZlwHRD0s41S"
      },
      "source": [
        "#@title  { vertical-output: true, display-mode: \"both\" }\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "def data_object(atoms: ase.Atoms, num_atoms=54):\n",
        "  \n",
        "  n = atoms.get_global_number_of_atoms()\n",
        "\n",
        "  if n == 1: # one atom structure - need to expand\n",
        "    atoms = extend_atoms(atoms, num_atoms)\n",
        "\n",
        "  n = atoms.get_global_number_of_atoms()\n",
        "\n",
        "  cell = torch.tensor(atoms.cell, dtype=DTYPE).to(device)\n",
        "  positions = torch.tensor(atoms.get_positions(), dtype=DTYPE).to(device)\n",
        "  \n",
        "  charges = [ NUCLEAR_CHARGE ] * len(positions)\n",
        "  charges = torch.tensor(charges, dtype=torch.long).to(device)\n",
        "\n",
        "  y = torch.tensor(atoms.info[\"energy\"], dtype=DTYPE).to(device)\n",
        "\n",
        "  return Data(charges=charges, x=positions, y=y, cell=cell, n=n)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sR_DYiE0s7xy"
      },
      "source": [
        "# DimeNet - Edited Version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPGAsYCKs_8e"
      },
      "source": [
        "**Changes done:**\n",
        "\n",
        "*   Added support to Periodic Boundary Conditions\n",
        "*   Added support to energy de-standardization\n",
        "*   Fixed a mistake made on the PyTorch Geometric implementation on the Embedding Block\n",
        "*   Fixed a mistake made on the original implementation of angles (swapped indices)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tvJkKVItCMO"
      },
      "source": [
        "#@title  { vertical-output: true, form-width: \"25%\" }\n",
        "from torch_geometric.nn import DimeNet\n",
        "from torch_geometric.nn.acts import swish\n",
        "from math import sqrt, pi as PI\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn import Linear, Embedding\n",
        "from torch_scatter import scatter\n",
        "from torch_sparse import SparseTensor\n",
        "from torch_geometric.nn import radius_graph\n",
        "from torch_geometric.data import download_url\n",
        "from torch_geometric.data.makedirs import makedirs\n",
        "\n",
        "from torch_geometric.nn.models.dimenet import Envelope\n",
        "from torch_geometric.nn.models.dimenet import BesselBasisLayer\n",
        "from torch_geometric.nn.models.dimenet import SphericalBasisLayer\n",
        "from torch_geometric.nn.models.dimenet import ResidualLayer\n",
        "from torch_geometric.nn.models.dimenet import InteractionBlock\n",
        "from torch_geometric.nn.models.dimenet import OutputBlock\n",
        "\n",
        "from torch_geometric.nn.models.dimenet_utils import bessel_basis, real_sph_harm\n",
        "\n",
        "try:\n",
        "    import sympy as sym\n",
        "except ImportError:\n",
        "    sym = None\n",
        "\n",
        "import os\n",
        "try:\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "    import tensorflow as tf\n",
        "except ImportError:\n",
        "    tf = None\n",
        "\n",
        "\n",
        "qm9_target_dict = {\n",
        "    0: 'mu',\n",
        "    1: 'alpha',\n",
        "    2: 'homo',\n",
        "    3: 'lumo',\n",
        "    5: 'r2',\n",
        "    6: 'zpve',\n",
        "    7: 'U0',\n",
        "    8: 'U',\n",
        "    9: 'H',\n",
        "    10: 'G',\n",
        "    11: 'Cv',\n",
        "}\n",
        "\n",
        "# Implement PBC\n",
        "from ase.neighborlist import neighbor_list \n",
        "from ase import Atoms\n",
        "\n",
        "\n",
        "class EmbeddingBlock(torch.nn.Module):\n",
        "    def __init__(self, num_radial, hidden_channels, act=swish):\n",
        "        super(EmbeddingBlock, self).__init__()\n",
        "        self.act = act\n",
        "\n",
        "        self.emb = Embedding(95, hidden_channels)\n",
        "        self.lin_rbf = Linear(num_radial, hidden_channels)\n",
        "        self.lin = Linear(3 * hidden_channels, hidden_channels)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.emb.weight.data.uniform_(-sqrt(3), sqrt(3))\n",
        "        self.lin_rbf.reset_parameters()\n",
        "        self.lin.reset_parameters()\n",
        "\n",
        "    def forward(self, x, rbf, i, j):\n",
        "        x = self.emb(x)\n",
        "        #rbf = self.act(self.lin_rbf(rbf)) # FIX: this should not have an activation function\n",
        "        rbf = self.lin_rbf(rbf)\n",
        "        return self.act(self.lin(torch.cat([x[i], x[j], rbf], dim=-1)))\n",
        "\n",
        "class DimeNet2(DimeNet):\n",
        "  \n",
        "  def __init__(self, hidden_channels, out_channels, num_blocks, num_bilinear,\n",
        "                 num_spherical, num_radial, cutoff=5.0, envelope_exponent=5,\n",
        "                 num_before_skip=1, num_after_skip=2, num_output_layers=3,\n",
        "                 act=swish,\n",
        "                 mean=None, std=None):\n",
        "          super(DimeNet, self).__init__()\n",
        "\n",
        "          self.cutoff = cutoff\n",
        "\n",
        "          #set mean and standard deviation of energies\n",
        "          self.mean = mean \n",
        "          self.std = std\n",
        "\n",
        "          # padding used for PBCs\n",
        "          self.padding = torch.nn.ConstantPad2d((0,6,0,0), 0)\n",
        "\n",
        "          if sym is None:\n",
        "              raise ImportError('Package `sympy` could not be found.')\n",
        "\n",
        "          self.num_blocks = num_blocks\n",
        "\n",
        "          self.rbf = BesselBasisLayer(num_radial, cutoff, envelope_exponent)\n",
        "          self.sbf = SphericalBasisLayer(num_spherical, num_radial, cutoff,\n",
        "                                          envelope_exponent)\n",
        "\n",
        "          self.emb = EmbeddingBlock(num_radial, hidden_channels, act)\n",
        "\n",
        "          self.output_blocks = torch.nn.ModuleList([\n",
        "              OutputBlock(num_radial, hidden_channels, out_channels,\n",
        "                          num_output_layers, act) for _ in range(num_blocks + 1)\n",
        "          ])\n",
        "\n",
        "          self.interaction_blocks = torch.nn.ModuleList([\n",
        "              InteractionBlock(hidden_channels, num_bilinear, num_spherical,\n",
        "                                num_radial, num_before_skip, num_after_skip, act)\n",
        "              for _ in range(num_blocks)\n",
        "          ])\n",
        "\n",
        "          self.reset_parameters()\n",
        "\n",
        "  def pbc_edges(self, z, pos, cell, batch):\n",
        "          if cell is None:\n",
        "            return\n",
        "\n",
        "          tmp_z = z.cpu()\n",
        "          tmp_pos = pos.cpu()\n",
        "          tmp_cell = cell.cpu()\n",
        "          nh1_tmp = np.array([]) # will contain all connection from node i\n",
        "          nh2_tmp = np.array([]) # .. to node j\n",
        "          dist_tmp = np.array([]) # distances between (i,j)\n",
        "          shift_cells_tmp = None # bravais lattice multiplied by shift for the connection\n",
        "\n",
        "          if batch is not None: #batch input\n",
        "            tmp_batch = np.array(batch.cpu())\n",
        "            batch_size = []\n",
        "            found_b = []\n",
        "            for b in tmp_batch: # create an array with each element being the dim of the corresponding index batch\n",
        "              if b not in found_b:\n",
        "                found_b.append(b)\n",
        "                batch_size.append((tmp_batch == b).sum())\n",
        "\n",
        "            for i in range(len(batch_size)):\n",
        "              prev_sum = sum(batch_size[:i])\n",
        "              current_z = tmp_z[prev_sum:batch_size[i]+prev_sum]\n",
        "              # create the atomic structure\n",
        "              atms = Atoms(charges=current_z, \n",
        "                           positions=tmp_pos[prev_sum:batch_size[i]+prev_sum], \n",
        "                           cell=tmp_cell[3*i:3*(i+1)], pbc=True) \n",
        "\n",
        "              # get the connections for the atomic structure w/ distances and shift\n",
        "              nh1, nh2, dist, shift = neighbor_list(\"ijdS\", atms, \n",
        "                                             self.cutoff, \n",
        "                                             self_interaction=False) \n",
        "\n",
        "              nh1 = nh1 + prev_sum # adds the number of previous elements to the atom index\n",
        "              nh2 = nh2 + prev_sum\n",
        "\n",
        "              nh1_tmp = np.concatenate((nh1_tmp, np.array(nh1)))\n",
        "              nh2_tmp = np.concatenate((nh2_tmp, np.array(nh2)))\n",
        "              dist_tmp = np.concatenate((dist_tmp, np.array(dist)))\n",
        "\n",
        "              # Mult cells array (9 elements each) for each connection element in the batch\n",
        "              cell_arr = np.asarray(tmp_cell[3*i:3*(i+1)]).reshape(-1)\n",
        "              repeat = np.tile(cell_arr, (len(dist), 1))\n",
        "\n",
        "              # multiply cell values by shift\n",
        "              repeat[:, 0:3] = (repeat[:, 0:3].T * shift[:, 0]).T\n",
        "              repeat[:, 3:6] = (repeat[:, 3:6].T * shift[:, 1]).T\n",
        "              repeat[:, 6:9] = (repeat[:, 6:9].T * shift[:, 2]).T\n",
        "\n",
        "              if shift_cells_tmp  is None:\n",
        "                shift_cells_tmp  = np.matrix(repeat)\n",
        "              else:\n",
        "                shift_cells_tmp  = np.concatenate((shift_cells_tmp, repeat))\n",
        "          else: # single cell input\n",
        "              # create the atomic structure\n",
        "              atms = Atoms(charges=tmp_z, \n",
        "                           positions=tmp_pos, \n",
        "                           cell=tmp_cell, pbc=True)\n",
        "\n",
        "              # get the connections for the atomic structure w/ distances and shift\n",
        "              nh1, nh2, dist, shift = neighbor_list(\"ijdS\", atms, \n",
        "                                             self.cutoff, \n",
        "                                             self_interaction=False)\n",
        "\n",
        "              nh1_tmp = np.concatenate((nh1_tmp, np.array(nh1)))\n",
        "              nh2_tmp = np.concatenate((nh2_tmp, np.array(nh2)))\n",
        "              dist_tmp = np.concatenate((dist_tmp, np.array(dist)))\n",
        "\n",
        "              # Mult cells array (9 elements each) for each connection element in the batch\n",
        "              cell_arr = np.asarray(tmp_cell).reshape(-1)\n",
        "              repeat = np.tile(cell_arr, (len(dist), 1))\n",
        "\n",
        "              # multiply cell values by shift\n",
        "              repeat[:,0:3] = (repeat[:, 0:3].T * shift[:, 0]).T\n",
        "              repeat[:,3:6] = (repeat[:, 3:6].T * shift[:, 1]).T\n",
        "              repeat[:,6:9] = (repeat[:, 6:9].T * shift[:, 2]).T\n",
        "\n",
        "              shift_cells_tmp = np.matrix(repeat)\n",
        "          return [torch.tensor(nh1_tmp, dtype = torch.long).to(z.device), \n",
        "                  torch.tensor(nh2_tmp, dtype = torch.long).to(z.device), \n",
        "                  torch.tensor(dist_tmp, dtype = DTYPE).to(z.device),\n",
        "                  torch.tensor(shift_cells_tmp, dtype = DTYPE).to(z.device)]\n",
        "            \n",
        "\n",
        "  def triplets(self, edge_index, num_nodes, shift_cells=None):\n",
        "        row, col = edge_index  # j->i\n",
        "\n",
        "        value = torch.arange(row.size(0), device=row.device)\n",
        "        adj_t = SparseTensor(row=col, col=row, value=value,\n",
        "                             sparse_sizes=(num_nodes, num_nodes))\n",
        "        adj_t_row = adj_t[row]\n",
        "\n",
        "        num_triplets = adj_t_row.set_value(None).sum(dim=1).to(torch.long)\n",
        "\n",
        "        # Node indices (k->j->i) for triplets.\n",
        "        idx_i = col.repeat_interleave(num_triplets)\n",
        "        idx_j = row.repeat_interleave(num_triplets)\n",
        "\n",
        "        if shift_cells is not None: # Update also the shift vectors\n",
        "          shift_cells = shift_cells.repeat_interleave(num_triplets, dim=0)\n",
        "\n",
        "        idx_k = adj_t_row.storage.col()\n",
        "\n",
        "        mask = (idx_i != idx_k)  # Remove i == k triplets.\n",
        "        idx_i, idx_j, idx_k = idx_i[mask], idx_j[mask], idx_k[mask]\n",
        "        if shift_cells is not None: # Remove also from the shift vector\n",
        "          shift_cells = shift_cells[mask]\n",
        "\n",
        "        # Edge indices (k-j, j->i) for triplets.\n",
        "        idx_kj = adj_t_row.storage.value()[mask]\n",
        "        idx_ji = adj_t_row.storage.row()[mask]\n",
        "\n",
        "        return col, row, idx_i, idx_j, idx_k, idx_kj, idx_ji, shift_cells\n",
        "\n",
        "  def forward(self, z, pos, cell=None, batch=None):\n",
        "        \n",
        "        edge_index = []\n",
        "        dist = []\n",
        "        shift_cells = None\n",
        "        if cell is not None: # implement PBC\n",
        "          r1, r2, dist, shift_cells = self.pbc_edges(z, pos, cell, batch)\n",
        "          edge_index = [r1, r2]\n",
        "        else: # old method without PBC\n",
        "          edge_index = radius_graph(pos, r=self.cutoff, batch=batch)\n",
        "\n",
        "        i, j, idx_i, idx_j, idx_k, idx_kj, idx_ji, shift_cells = self.triplets(\n",
        "            edge_index, num_nodes=z.size(0), shift_cells=shift_cells)        \n",
        "\n",
        "        # Calculate distances.\n",
        "        if cell is None: # calculate distance without PBC\n",
        "          dist = (pos[i] - pos[j]).pow(2).sum(dim=-1).sqrt()\n",
        "          \n",
        "        # Define atoms position \n",
        "        pos_i = pos[idx_i]\n",
        "        pos_j = pos[idx_j] # central atom\n",
        "        pos_k = pos[idx_k]\n",
        "        \n",
        "        if cell is not None: # Fix coordinates for PBCs\n",
        "          pos_i = pos_i + shift_cells[:, 0:3] + shift_cells[:, 3:6] + shift_cells[:, 6:9]\n",
        "          pos_k = pos_k + shift_cells[:, 0:3] + shift_cells[:, 3:6] + shift_cells[:, 6:9]\n",
        "\n",
        "        # Calculate angles - with some Fixes to indexes compared to the orig. version\n",
        "        pos_ji, pos_kj = pos_j - pos_i, pos_k - pos_j\n",
        "\n",
        "        a = (pos_ji * pos_kj).sum(dim=-1)\n",
        "        b = torch.cross(pos_ji, pos_kj).norm(dim=-1)\n",
        "        angle = torch.atan2(b, a)\n",
        "\n",
        "        rbf = self.rbf(dist)\n",
        "        sbf = self.sbf(dist, angle, idx_kj)\n",
        "\n",
        "        # Embedding block.\n",
        "        x = self.emb(z, rbf, i, j)\n",
        "        P = self.output_blocks[0](x, rbf, i, num_nodes=pos.size(0))\n",
        "\n",
        "        # Interaction blocks.\n",
        "        for interaction_block, output_block in zip(self.interaction_blocks,\n",
        "                                                   self.output_blocks[1:]):\n",
        "            x = interaction_block(x, rbf, sbf, idx_kj, idx_ji)\n",
        "            P += output_block(x, rbf, i, num_nodes=pos.size(0))\n",
        "\n",
        "        # Energy de-standardization\n",
        "        if self.std is not None and self.mean is not None:\n",
        "          P = P * self.std + self.mean\n",
        "\n",
        "        res = P.sum(dim=0) if batch is None else scatter(P, batch, dim=0)\n",
        "        return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rO0BwB0JtIdx"
      },
      "source": [
        "# Network Initialization (Load Trained Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DQjrSAvtLWM"
      },
      "source": [
        "# Uncomment only one triple [modelPath, HAS_PBC, model]\n",
        "# HAS_PBC: set to True if the PBC was trained using PBCs\n",
        "\n",
        "'''\n",
        "modelName = \"DimeNet DB1 NO PBC\"\n",
        "modelPath = BASE_PATH + 'trained/db1-nopbc-pretrained.model'\n",
        "HAS_PBC = False\n",
        "model = DimeNet2(hidden_channels=128, out_channels=1, num_blocks=7, num_bilinear=6, num_spherical=5, num_radial=5, cutoff=3.5, std=0.22314909777243813, mean=-3460.810642670331).to(device)\n",
        "'''\n",
        "\n",
        "'''\n",
        "modelName = \"DimeNet DB1-8 NO PBC\"\n",
        "modelPath = BASE_PATH + 'trained/all-nopbc-pretrained.model'\n",
        "HAS_PBC = False\n",
        "model = DimeNet2(hidden_channels=128, out_channels=1, num_blocks=7, num_bilinear=6, num_spherical=5, num_radial=5, cutoff=3.5, std=0.16576383029449515, mean=-3460.825847482401).to(device)\n",
        "'''\n",
        "\n",
        "'''\n",
        "modelName = \"DimeNet DB1 PBC\"\n",
        "modelPath = BASE_PATH + 'trained/db1-pbc-pretrained.model'\n",
        "HAS_PBC = True\n",
        "model = DimeNet2(hidden_channels=128, out_channels=1, num_blocks=7, num_bilinear=6, num_spherical=5, num_radial=5, cutoff=3.5, std=0.22314909777243813, mean=-3460.810642670331).to(device)\n",
        "'''\n",
        "\n",
        "modelName = \"DimeNet DB1-8 PBC\"\n",
        "modelPath = BASE_PATH + 'trained/all-pbc-pretrained.model'\n",
        "HAS_PBC = True\n",
        "model = DimeNet2(hidden_channels=128, out_channels=1, num_blocks=7, num_bilinear=8, num_spherical=7, num_radial=6, cutoff=3.5, std=0.16576383029449515, mean=-3460.825847482401).to(device)\n",
        "\n",
        "\n",
        "\n",
        "model.load_state_dict(torch.load(modelPath))\n",
        "model = model.to(device)\n",
        "model = model.double() # necessary if the model was trained using the float64 DTYPE\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXgCVjcftsZD"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgI97H_2tt0c"
      },
      "source": [
        "## Equation of State Curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Hi6g8O9vBMt"
      },
      "source": [
        "We want the network to be able to reproduce the Equation of State (EOS) Curve, that is the Volume-Energy curve reported in FIG.2 of [Dragoni's Paper](https://arxiv.org/abs/1706.10229)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAjdpzdnt443"
      },
      "source": [
        "*dataset_nocut.xyz* is provided in this repository.\n",
        "It's a set of perfect 1-atom structures BCCs, that is with the Bravais Lattice made like this:\n",
        "\n",
        "*   a1 = <a, 0, 0>\n",
        "*   a2 = <0, a, 0>\n",
        "*   a3 = <a/2, a/2, a/2>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TBM-fuPt0_W"
      },
      "source": [
        "# load BCC dataset that we want to predict\n",
        "\n",
        "volumes = []\n",
        "predictions = []\n",
        "\n",
        "predict_reticoli = []\n",
        "tmp_db = read(path2data + 'dataset_nocut.xyz', index=\":\")\n",
        "\n",
        "original_volumes = []\n",
        "for db in tmp_db:\n",
        "  original_volumes.append(db.cell.volume)\n",
        "\n",
        "predict_reticoli = list(map(data_object, tmp_db))\n",
        "\n",
        "print(predict_reticoli)\n",
        "print(original_volumes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RyYZf1tv-aP"
      },
      "source": [
        "# load baseline results (GAP and DFT) - provided with the repository\n",
        "\n",
        "dft_v = torch.load(path2data + \"dft_fig2_volumes.pt\")\n",
        "dft_e = torch.load(path2data + \"dft_fig2_energies.pt\")\n",
        "gap_v = torch.load(path2data + \"gap_fig2_volumes.pt\")\n",
        "gap_e = torch.load(path2data + \"gap_fig2_energies.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8EfkKzzvmju"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Bigger fonts for thesis images\n",
        "'''\n",
        "plt.rcParams.update({'font.size':25})\n",
        "plt.rcParams.update({'axes.titlesize':30})\n",
        "plt.rcParams.update({'figure.titlesize':30})\n",
        "plt.rcParams.update({'xtick.labelsize':15})\n",
        "plt.rcParams.update({'ytick.labelsize':15})\n",
        "plt.rcParams.update({'legend.fontsize':25})\n",
        "'''\n",
        "\n",
        "predictions = []\n",
        "\n",
        "# get the predictions for BCCs on the trained model\n",
        "if len(volumes) == 0:\n",
        "  test_loader = DataLoader(predict_reticoli, batch_size=1, shuffle=False)\n",
        "  for data in predict_reticoli:\n",
        "    xyz = np.array(data.cell.cpu())\n",
        "\n",
        "  for data in test_loader:\n",
        "    with torch.no_grad():\n",
        "      if HAS_PBC:\n",
        "        out = model(data.charges, data.x, data.cell, data.batch)\n",
        "      else:\n",
        "        out = model(data.charges, data.x, batch=data.batch)\n",
        "      \n",
        "      out = out.squeeze(1)\n",
        "      predicted_energy = float(out.view(-1))\n",
        "      predictions.append(predicted_energy / int(data.n)) # divide the output by the number of atoms of the structure\n",
        "\n",
        "\n",
        "energies = predictions.copy()\n",
        "\n",
        "\n",
        "\n",
        "print(\"Plotted VO / Energies:\")\n",
        "print(original_volumes)\n",
        "print(energies)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16,10))\n",
        "plt.cla()\n",
        "ax.set_xlim(10.99, 12)\n",
        "ax.set_ylim(-3460934.301071031, -3460914.9599393304)\n",
        "\n",
        "ax.set_title(modelName)\n",
        "plt.xlabel(\"V\")\n",
        "plt.ylabel(\"E\")\n",
        "\n",
        "\n",
        "b = ax.scatter(original_volumes, [(en*1000) for en in energies], color=\"blue\")\n",
        "ax.plot(original_volumes, [(en*1000) for en in energies], color=\"blue\")\n",
        "b.set_label('DimeNet')\n",
        "\n",
        "c = ax.scatter(dft_v, dft_e, color=\"black\")\n",
        "ax.plot(dft_v, dft_e, color=\"black\")\n",
        "\n",
        "c.set_label('DFT')\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjJUma0FwW_I"
      },
      "source": [
        "## Bain Path Curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3Icjzh1wao0"
      },
      "source": [
        "We want the network to be able to reproduce the Bain Path Curve, that is the c/a ratio / Energy curve reported in FIG.3 of [Dragoni's Paper](https://arxiv.org/abs/1706.10229)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2ERIv4owwqd"
      },
      "source": [
        "# Load DFT baseline\n",
        "\n",
        "dft_fig3_ca = []\n",
        "dft_fig3_en = []\n",
        "f = open(path2data+\"dft_fig3.csv\", \"r\")\n",
        "lines = f.read().split(\"\\n\")\n",
        "for line in lines:\n",
        "  if line.strip() == \"\":\n",
        "    continue\n",
        "  dft_fig3_ca.append(float(line.split(\";\")[0].replace(\",\", \".\").strip()))\n",
        "  dft_fig3_en.append(float(line.split(\";\")[1].replace(\",\", \".\").strip()))\n",
        "\n",
        "out = \"\"\n",
        "print(dft_fig3_ca)\n",
        "print(dft_fig3_en)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZyLZHtJw_St"
      },
      "source": [
        "# Constant Volume Method: generate the 54 atoms structures by varying the c/a ratio\n",
        "\n",
        "from ase.atoms import Cell\n",
        "import math\n",
        "\n",
        "predictions_vol = []\n",
        "predictions = []\n",
        "\n",
        "predict_reticoli_single = []\n",
        "tmp_dataset = read(path2data + 'DB1.xyz', index=\":\")\n",
        "\n",
        "# Create cells by variying the c/a ratio from 0.5 to 2.0 by a step of 0.02 (coeff)\n",
        "a = 2.83477\n",
        "reticolo = tmp_dataset[0]\n",
        "\n",
        "coeff = np.arange(0.5,2.05,0.02)\n",
        "\n",
        "predict_reticoli_vol = []\n",
        "\n",
        "dime_x_plot_m1 = []\n",
        "for sr_ in coeff:\n",
        "  sr = sr_.item()\n",
        "  r = sr**(2/3)\n",
        "  a_c = r**(-1)\n",
        "\n",
        "  cell1 = \"{} {} {}\".format(math.sqrt(a_c)*a, 0, 0)\n",
        "  cell2 = \"{} {} {}\".format(0, math.sqrt(a_c)*a, 0)\n",
        "  cell3 = \"{} {} {}\".format(math.sqrt(a_c)*a/2, math.sqrt(a_c)*a/2, (r)*a/2)\n",
        "\n",
        "  tmp_ret = reticolo.copy()\n",
        "  tmp_ret.cell = Cell([ [ float(x.strip()) for x in cell1.split(' ')], [ float(x.strip()) for x in cell2.split(' ')], [ float(x.strip()) for x in cell3.split(' ')] ])\n",
        "  predict_reticoli_vol.append(data_object(tmp_ret))\n",
        "\n",
        "  dime_x_plot_m1.append(sr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrZizp-NxjS9"
      },
      "source": [
        "# Volume Optimization Method: generate like before but also vary based on \n",
        "#                             a \"r\" coefficent on last term of Bravais lattices\n",
        "\n",
        "\n",
        "predict_reticoli_single = []\n",
        "tmp_dataset = read(path2data + 'DB1.xyz', index=\":\")\n",
        "\n",
        "\n",
        "a = 2.83477\n",
        "reticolo = tmp_dataset[0]\n",
        "\n",
        "predict_reticoli = []\n",
        "# extra variation on the last Bravais coefficent\n",
        "r = np.arange(0.7,2.0,0.02)\n",
        "\n",
        "coeff = np.arange(0.5,2.05,0.02)\n",
        "dime_x_plot_m2 = []\n",
        "for sr_ in coeff:\n",
        "  sr = sr_.item()\n",
        "  r = sr**(2/3)\n",
        "  a_c = r**(-1)\n",
        "  a_tmp = np.arange(0.95*a,1.05*a,0.02)\n",
        "  tmp_arr = []\n",
        "  for current_a in a_tmp:\n",
        "    cell1 = \"{} {} {}\".format(math.sqrt(a_c)*current_a, 0, 0)\n",
        "    cell2 = \"{} {} {}\".format(0, math.sqrt(a_c)*current_a, 0)\n",
        "    cell3 = \"{} {} {}\".format(math.sqrt(a_c)*current_a/2, math.sqrt(a_c)*current_a/2, (r)*current_a/2)\n",
        "    tmp_ret = reticolo.copy()\n",
        "    tmp_ret.cell = Cell([ [ float(x.strip()) for x in cell1.split(' ')], [ float(x.strip()) for x in cell2.split(' ')], [ float(x.strip()) for x in cell3.split(' ')] ])\n",
        "    tmp_arr.append(data_object(tmp_ret))\n",
        "\n",
        "  predict_reticoli.append(tmp_arr)\n",
        "  dime_x_plot_m2.append(sr)\n",
        "\n",
        "\n",
        "print(predict_reticoli)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bePDJTZLz0Y9"
      },
      "source": [
        "### Draw Figure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy6dcsEFz2M0"
      },
      "source": [
        "Notice that the network performs well on the [0.8 - 1.2] range - where the tain data is focused on. On other ranges the network is extrapolating."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV9PTPJmyneO"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Predictions for the Method 2, take only the best results (lower energy)\n",
        "all_points = []\n",
        "all_points_x = []\n",
        "elements = 0\n",
        "if len(predictions) == 0:\n",
        "  for topredict in predict_reticoli:\n",
        "    test_loader = DataLoader(topredict, batch_size=1, shuffle=False)\n",
        "    tmp_predictions = []\n",
        "    tmp_a = []\n",
        "    for data in test_loader:\n",
        "      with torch.no_grad():\n",
        "        if HAS_PBC:\n",
        "          out = model(data.charges, data.x, data.cell, data.batch)\n",
        "        else:\n",
        "          out = model(data.charges, data.x, batch=data.batch)\n",
        "        out = out.squeeze(1)\n",
        "        predicted_energy = float(out.view(-1))\n",
        "        tmp_predictions.append(predicted_energy / int(data.n)) # divide by the atoms of the structure\n",
        "        tmp_a.append(data.x[0])\n",
        "\n",
        "    best_energy = 9999\n",
        "    for i in range(len(tmp_predictions)):\n",
        "      all_points.append(tmp_predictions[i])\n",
        "      all_points_x.append(dime_x_plot_m2[elements])\n",
        "      if tmp_predictions[i] < best_energy:\n",
        "        best_energy = tmp_predictions[i]\n",
        "\n",
        "    predictions.append(best_energy)\n",
        "    elements = elements + 1\n",
        "\n",
        "# Predictions for the Method 1\n",
        "if len(predictions_vol) == 0:\n",
        "  test_loader = DataLoader(predict_reticoli_vol, batch_size=1, shuffle=False)\n",
        "  for data in test_loader:\n",
        "    with torch.no_grad():\n",
        "      if HAS_PBC:\n",
        "        out = model(data.charges, data.x, data.cell, data.batch)\n",
        "      else:\n",
        "        out = model(data.charges, data.x, batch=data.batch)\n",
        "      out = out.squeeze(1)\n",
        "      predicted_energy = float(out.view(-1))\n",
        "      predictions_vol.append(predicted_energy / int(data.n))\n",
        "\n",
        "    \n",
        "#standardize energy\n",
        "energies = predictions.copy()\n",
        "energies_vol = predictions_vol.copy()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(16,10))\n",
        "plt.cla()\n",
        "\n",
        "ax.set_title(modelName)\n",
        "plt.xlabel(\"c/a\")\n",
        "plt.ylabel(\"E\")\n",
        "\n",
        "#ax.set_xlim(10.95, 12.05)\n",
        "test = [en for en in dft_fig3_en]\n",
        "\n",
        "ax.set_ylim(min(test)-50, max(test)+150)\n",
        "ax.set_xlim(0.7, 2.1)\n",
        "\n",
        "# Plot DFT Baseline \n",
        "c = ax.scatter(dft_fig3_ca, [en for en in dft_fig3_en], color=\"black\")\n",
        "ax.plot(dft_fig3_ca, [en for en in dft_fig3_en], color=\"black\")\n",
        "c.set_label(\"DFT\")\n",
        "\n",
        "print(\"Dimenet Constant Volume:\")\n",
        "print(dime_x_plot_m1)\n",
        "print([(en*1000) for en in energies])\n",
        "print(\"----\")\n",
        "print(\"Dimenet Volume Optimization:\")\n",
        "print(dime_x_plot_m2)\n",
        "print([(en*1000) for en in energies_vol])\n",
        "\n",
        "d = ax.scatter(dime_x_plot_m2, [(en*1000) for en in energies], color=\"blue\")\n",
        "ax.plot(dime_x_plot_m2, [(en*1000) for en in energies], color=\"blue\")\n",
        "d.set_label(\"DimeNet Vol. Optimization\")\n",
        "\n",
        "e = ax.scatter(dime_x_plot_m1, [(en*1000) for en in energies_vol], color=\"red\")\n",
        "ax.plot(dime_x_plot_m1, [(en*1000) for en in energies_vol], color=\"red\")\n",
        "e.set_label(\"DimeNet Costant Vol.\")\n",
        "\n",
        "\n",
        "# Draw vertical lines\n",
        "plt.axvline(x=0.8, linestyle='--', label=\"bct\")\n",
        "plt.axvline(x=1.0, linestyle='--', color='orange', label=\"bcc\")\n",
        "plt.axvline(x=math.sqrt(2), linestyle='--', color='brown', label=\"fcc\")\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3utlZItJ0FNN"
      },
      "source": [
        "## Periodic Boundary Conditions Sanity Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "414LsPgp0LB3"
      },
      "source": [
        "Here we are testing the correct implementation of PBCs on the network by creating a 4-atoms structure, 16-atoms structure, 54-atoms structure and a 128-atoms structure based on the same Bravais lattice. \n",
        "\n",
        "The two predicted energies, divided by the number of atoms in the structure, should be roughly the same if PBCs are working correctly. Notice that this sanity check should be performed only when testing a PBC-trained model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXky84KS0V3l"
      },
      "source": [
        "db1 = read(path2data + 'DB1.xyz', index=\":\")\n",
        "first_4 = data_object(db1[0], num_atoms=4)\n",
        "first_128 = data_object(db1[0], num_atoms=128)\n",
        "\n",
        "print(first_4)\n",
        "print(first_128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8aQPNJ50qlv"
      },
      "source": [
        "e_4 = 0\n",
        "e_128 = 0\n",
        "\n",
        "test_loader = DataLoader([first_4], batch_size=1, shuffle=False)\n",
        "for data in test_loader:\n",
        "  with torch.no_grad():\n",
        "    if HAS_PBC:\n",
        "      out = model(data.charges, data.x, cell=data.cell, batch=data.batch)\n",
        "    else:\n",
        "      out = model(data.charges, data.x, batch=data.batch)\n",
        "    out = out.squeeze(1)\n",
        "    predicted_energy = float(out.view(-1))\n",
        "    e_4 = predicted_energy\n",
        "\n",
        "test_loader = DataLoader([first_128], batch_size=1, shuffle=False)\n",
        "for data in test_loader:\n",
        "  with torch.no_grad():\n",
        "    if HAS_PBC:\n",
        "      out = model(data.charges, data.x, cell=data.cell, batch=data.batch)\n",
        "    else:\n",
        "      out = model(data.charges, data.x, batch=data.batch)\n",
        "    out = out.squeeze(1)\n",
        "    predicted_energy = float(out.view(-1))\n",
        "    e_128 = predicted_energy\n",
        "\n",
        "print(\"e_4: \", e_4)\n",
        "print(\"e_4 / 4: \", (e_4 / 4))\n",
        "print(\"e_128: \", e_128)\n",
        "print(\"e_128 / 128: \", (e_128 / 128))\n",
        "\n",
        "print(\"error: \", abs((e_128 / 128) - (e_4 / 4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19sCvlJw029_"
      },
      "source": [
        "## Vacancy Formation Energy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaN1n_Ym086c"
      },
      "source": [
        "Here we want to predict the missing energy caused by a single-vacancy inside the structure (the removal of one atom).\n",
        "\n",
        "The datasets used for this test are given with the repository.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVQ3fsu71Oz9"
      },
      "source": [
        "# Load the models and predict energies\n",
        "bulk_128_dataset = read(path2data + 'bulk_128atoms.xyz', index=\":\")\n",
        "vac_127_dataset = read(path2data + 'vac_127atoms.xyz', index=\":\")\n",
        "bulk_54_dataset = read(path2data + 'bulk_54atoms.xyz', index=\":\")\n",
        "vac_53_dataset = read(path2data + 'vac_53atoms.xyz', index=\":\")\n",
        "\n",
        "bulk_lattice_128 = []\n",
        "vac_lattice_127 = []\n",
        "for lattice in bulk_128_dataset:\n",
        "    bulk_lattice_128.append(data_object(lattice))\n",
        "\n",
        "for lattice in vac_127_dataset:\n",
        "  vac_lattice_127.append(data_object(lattice))\n",
        "\n",
        "\n",
        "print(bulk_lattice_128)\n",
        "print(vac_lattice_127)\n",
        "\n",
        "\n",
        "bulk_lattice_54 = []\n",
        "vac_lattice_53 = []\n",
        "for lattice in bulk_54_dataset:\n",
        "    bulk_lattice_54.append(data_object(lattice))\n",
        "\n",
        "for lattice in vac_53_dataset:\n",
        "  vac_lattice_53.append(data_object(lattice))\n",
        "\n",
        "print(bulk_lattice_54)\n",
        "print(vac_lattice_53)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pn9XqER1_bF"
      },
      "source": [
        "#Predict energies for the 128 / 127 configurations\n",
        "target = 2.48920984\n",
        "e_total = 0\n",
        "e_total_v = 0\n",
        "\n",
        "test_loader = DataLoader(bulk_lattice_128, batch_size=1, shuffle=False)\n",
        "for data in test_loader:\n",
        "  with torch.no_grad():\n",
        "    if HAS_PBC:\n",
        "      out = model(data.charges, data.x, data.cell, data.batch)\n",
        "    else:\n",
        "      out = model(data.charges, data.x, batch=data.batch)\n",
        "    out = out.squeeze(1)\n",
        "    predicted_energy = float(out.view(-1))\n",
        "    e_total = predicted_energy\n",
        "\n",
        "test_loader = DataLoader(vac_lattice_127, batch_size=1, shuffle=False)\n",
        "for data in test_loader:\n",
        "  with torch.no_grad():\n",
        "    if HAS_PBC:\n",
        "      out = model(data.charges, data.x, data.cell, data.batch)\n",
        "    else:\n",
        "      out = model(data.charges, data.x, batch=data.batch)\n",
        "    out = out.squeeze(1)\n",
        "    predicted_energy = float(out.view(-1))\n",
        "    e_total_v = predicted_energy\n",
        "\n",
        "\n",
        "print(\"E_Total (128 / 127)\", e_total)\n",
        "print(\"E_Total_v (128 / 127)\", e_total_v)\n",
        "print(\"\")\n",
        "\n",
        "e_v = e_total_v - e_total * (128 - 1) / 128\n",
        "print(\"E_v (128 / 127)\", e_v)\n",
        "print(\"error %\", abs(((target - e_v) / target) * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaYjSq7V2KNV"
      },
      "source": [
        "#Predict energies for the 54 / 53 configurations\n",
        "target = 2.27723546\n",
        "e_total = 0\n",
        "e_total_v = 0\n",
        "\n",
        "test_loader = DataLoader(bulk_lattice_54, batch_size=1, shuffle=False)\n",
        "for data in test_loader:\n",
        "  with torch.no_grad():\n",
        "    if HAS_PBC:\n",
        "      out = model(data.charges, data.x, data.cell, data.batch)\n",
        "    else:\n",
        "      out = model(data.charges, data.x, batch=data.batch)\n",
        "    out = out.squeeze(1)\n",
        "    predicted_energy = float(out.view(-1))\n",
        "    e_total = predicted_energy\n",
        "\n",
        "test_loader = DataLoader(vac_lattice_53, batch_size=1, shuffle=False)\n",
        "for data in test_loader:\n",
        "  with torch.no_grad():\n",
        "    if HAS_PBC:\n",
        "      out = model(data.charges, data.x, data.cell, data.batch)\n",
        "    else:\n",
        "      out = model(data.charges, data.x, batch=data.batch)\n",
        "    out = out.squeeze(1)\n",
        "    predicted_energy = float(out.view(-1))\n",
        "    e_total_v = predicted_energy\n",
        "\n",
        "\n",
        "print(\"E_Total (54 / 53)\", e_total)\n",
        "print(\"E_Total_v (54 / 53)\", e_total_v)\n",
        "print(\"\")\n",
        "\n",
        "e_v = e_total_v - e_total * (54 - 1) / 54\n",
        "print(\"E_v (54 / 53)\", e_v)\n",
        "print(\"error %\", abs(((target - e_v) / target) * 100))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}